{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPHPEkGDKwBAnluksJ9jb8O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iffraah96/Deep-Learning-AI-ITAI-2376-/blob/main/Virtual_AI_Research_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODULE 1: Input Processor**\n",
        "\n",
        "Classify user input into one (or more) of the following intents:\n",
        "\n",
        "1. \"search\": Find papers based on a topic.\n",
        "2. \"summarize\": Summarize a given paper or abstract.\n",
        "3. \"connect\": Find relationships between sources.\n",
        "4. \"cite\": Generate APA/MLA citations."
      ],
      "metadata": {
        "id": "xijYY67ZPbr6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0H_PioUF6wa"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def input_processor(user_input):\n",
        "    user_input = user_input.lower().strip()\n",
        "\n",
        "    tasks = {\n",
        "        \"search\": [\n",
        "            r'\\b(find|search|get|look for|collect|gather|explore)\\b',\n",
        "            r'\\b(paper|article|source|research|study|topic)\\b'\n",
        "        ],\n",
        "        \"summarize\": [\n",
        "            r'\\b(summarize|summarise|summary|give me a summary|what is this about)\\b'\n",
        "        ],\n",
        "        \"connect\": [\n",
        "            r'\\b(connection|relationship|link|relate|association)\\b',\n",
        "            r'\\bhow (are|do)\\b.*\\b(related|connected|link)\\b'\n",
        "        ],\n",
        "        \"cite\": [\n",
        "            r'\\b(cite|citation|apa|mla|format|how do i cite|reference)\\b'\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    detected = []\n",
        "    for task, patterns in tasks.items():\n",
        "        for pattern in patterns:\n",
        "            if re.search(pattern, user_input):\n",
        "                detected.append(task)\n",
        "                break  # no need to match more patterns for same task\n",
        "\n",
        "    if not detected:\n",
        "        detected = [\"search\"]  # fallback\n",
        "\n",
        "    return detected\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------------\n",
        "#-------------------------------------------Example------------------------------------------------------------\n",
        "#--------------------------------------------------------------------------------------------------------------\n",
        "print(input_processor(\"Can you help me find research on AI in education?\"))\n",
        "\n",
        "print(input_processor(\"Summarize this article on bias in facial recognition.\"))\n",
        "\n",
        "print(input_processor(\"What's the connection between these two papers?\"))\n",
        "\n",
        "print(input_processor(\"Format this citation in APA style\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODULE 2**: **Search Tool ‚Äî Academic Paper Search via Semantic Scholar API**\n",
        "\n",
        "\n",
        "Search for academic papers based on a topic using the Semantic Scholar API, and return:\n",
        "1. Title\n",
        "2. Abstract\n",
        "3. Authors\n",
        "4. Year\n",
        "5. URL"
      ],
      "metadata": {
        "id": "VlsRWbEbKLo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def search_semantic_scholar(query, limit=3):\n",
        "    base_url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
        "    params = {\n",
        "        \"query\": query,\n",
        "        \"limit\": limit,\n",
        "        \"fields\": \"title,abstract,authors,year,url\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        if data is None or \"data\" not in data:\n",
        "            print(\"‚ö†Ô∏è Unexpected response format:\")\n",
        "            print(response.text)\n",
        "            return {\"error\": \"Unexpected API response. Please try again later.\"}\n",
        "\n",
        "        results = []\n",
        "        for item in data[\"data\"]:\n",
        "            paper = {\n",
        "                \"title\": item.get(\"title\", \"N/A\"),\n",
        "                \"abstract\": item.get(\"abstract\", \"No abstract available.\"),\n",
        "                \"authors\": [a.get('name', 'Unknown') for a in item.get(\"authors\", [])],\n",
        "                \"year\": item.get(\"year\", \"N/A\"),\n",
        "                \"url\": item.get(\"url\", \"N/A\")\n",
        "            }\n",
        "            results.append(paper)\n",
        "\n",
        "        if not results:\n",
        "            return {\"error\": \"No papers found. Try a more specific query.\"}\n",
        "\n",
        "        return {\"papers\": results}\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return {\"error\": f\"Search failed due to a connection issue: {str(e)}\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"An unexpected error occurred: {str(e)}\"}\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------------\n",
        "#-------------------------------------------Example------------------------------------------------------------\n",
        "#--------------------------------------------------------------------------------------------------------------\n",
        "query = \"AI in Finance\"\n",
        "result = search_semantic_scholar(query)\n",
        "\n",
        "if \"papers\" in result:\n",
        "    for i, paper in enumerate(result[\"papers\"]):\n",
        "        print(f\"\\nüìò Paper {i+1}\")\n",
        "        print(\"Title:\", paper[\"title\"])\n",
        "        print(\"Year:\", paper[\"year\"])\n",
        "        print(\"Authors:\", \", \".join(paper[\"authors\"]))\n",
        "        print(\"Abstract:\", paper[\"abstract\"][:300], \"...\")\n",
        "        print(\"URL:\", paper[\"url\"])\n",
        "else:\n",
        "    print(\"‚ùå\", result[\"error\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "xYPEy8IYIcmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODULE 3: Summarizer Tool**\n",
        "\n",
        "Using HuggingFace Transformers\n",
        "\n",
        "\n",
        "Automatically summarize long abstracts or full texts into short, clear summaries using a pre-trained language model."
      ],
      "metadata": {
        "id": "6ipIItbNKEA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install & Import Libraries (Colab)\n",
        "!pip install transformers sentencepiece --quiet\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize Summarization Model\n",
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
        "\n",
        "#Define the Summarization Tool\n",
        "def summarize_text(text, max_input_tokens=512):\n",
        "    if not text or len(text.strip()) < 30:\n",
        "        return \"‚ö†Ô∏è Not enough content to summarize.\"\n",
        "\n",
        "    try:\n",
        "        input_text = text.strip().replace(\"\\n\", \" \")\n",
        "        input_text = input_text[:max_input_tokens]\n",
        "\n",
        "        input_length = len(input_text.split())\n",
        "        adjusted_max_length = max(30, int(input_length * 0.7))  # shorter than input\n",
        "\n",
        "        summary = summarizer(\n",
        "            input_text,\n",
        "            max_length=adjusted_max_length,\n",
        "            min_length=max(20, int(adjusted_max_length * 0.6)),\n",
        "            do_sample=False\n",
        "        )\n",
        "        return summary[0]['summary_text']\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Summarization failed: {str(e)}\"\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------------\n",
        "#-------------------------------------------Example------------------------------------------------------------\n",
        "#--------------------------------------------------------------------------------------------------------------\n",
        "results = search_semantic_scholar(\"AI in Finance\", limit=2)\n",
        "\n",
        "if \"papers\" in results:\n",
        "    for paper in results[\"papers\"]:\n",
        "        print(f\"\\nüìò {paper['title']}\")\n",
        "        summary = summarize_text(paper['abstract'])\n",
        "        print(\"üîç Summary:\", summary)\n",
        "else:\n",
        "    print(\"‚ùå\", results[\"error\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "8VybSb7JKDif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODULE 4: Memory Buffer - Store and retrieve**\n",
        "\n",
        "Papers found by the Search Tool\n",
        "\n",
        "Summaries created by the Summarizer Tool\n",
        "\n",
        "Any connections or citations\n",
        "\n",
        "User feedback (for RL-like learning later)"
      ],
      "metadata": {
        "id": "_pIrs7XSN2ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import uuid\n",
        "\n",
        "class MemoryBuffer:\n",
        "    def __init__(self):\n",
        "        self.memory = {}  # session-based storage\n",
        "\n",
        "    def _generate_id(self):\n",
        "        import uuid\n",
        "        return str(uuid.uuid4())[:8]  # short unique ID\n",
        "\n",
        "    def store_papers(self, query, papers):\n",
        "        from datetime import datetime\n",
        "        session_id = datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "        self.memory[session_id] = {\n",
        "            \"query\": query,\n",
        "            \"papers\": [],\n",
        "        }\n",
        "\n",
        "        for paper in papers:\n",
        "            paper_id = self._generate_id()\n",
        "            self.memory[session_id][\"papers\"].append({\n",
        "                \"id\": paper_id,\n",
        "                \"title\": paper['title'],\n",
        "                \"abstract\": paper['abstract'],\n",
        "                \"authors\": paper['authors'],\n",
        "                \"year\": paper['year'],\n",
        "                \"url\": paper['url'],\n",
        "                \"summary\": None,\n",
        "                \"citation\": None,\n",
        "                \"feedback\": None\n",
        "            })\n",
        "\n",
        "        return session_id\n",
        "\n",
        "    def store_summary(self, session_id, paper_id, summary):\n",
        "        for paper in self.memory.get(session_id, {}).get(\"papers\", []):\n",
        "            if paper[\"id\"] == paper_id:\n",
        "                paper[\"summary\"] = summary\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def store_citation(self, session_id, paper_id, citation):\n",
        "        for paper in self.memory.get(session_id, {}).get(\"papers\", []):\n",
        "            if paper[\"id\"] == paper_id:\n",
        "                paper[\"citation\"] = citation\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def get_papers(self, session_id):\n",
        "        return self.memory.get(session_id, {}).get(\"papers\", [])\n",
        "\n",
        "    def get_summary(self, session_id, paper_id):\n",
        "        for paper in self.get_papers(session_id):\n",
        "            if paper[\"id\"] == paper_id:\n",
        "                return paper.get(\"summary\", None)\n",
        "        return None\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------------\n",
        "#-------------------------------------------Example------------------------------------------------------------\n",
        "#--------------------------------------------------------------------------------------------------------------\n",
        "# Step 1: Search and store\n",
        "results = search_semantic_scholar(\"machine learning in fraud detection\", limit=2)\n",
        "buffer = MemoryBuffer()\n",
        "\n",
        "if \"papers\" in results:\n",
        "    session = buffer.store_papers(\"machine learning in fraud detection\", results[\"papers\"])\n",
        "    papers = buffer.get_papers(session)\n",
        "\n",
        "    for paper in papers:\n",
        "        print(f\"\\nüìò {paper['title']} ({paper['id']})\")\n",
        "        summary = summarize_text(paper['abstract'])\n",
        "        buffer.store_summary(session, paper['id'], summary)\n",
        "        print(\"üîç Summary:\", summary)\n"
      ],
      "metadata": {
        "id": "WAUbKmDuN-1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODULE 5: Citation Formatter (APA Style)**\n",
        "\n",
        "Format papers stored in memory into APA-style citations using their:\n",
        "\n",
        "1. Authors\n",
        "2. Year\n",
        "3. Title\n",
        "4. URL\n",
        "\n",
        "Basic APA Format:\n",
        "\n",
        "'AuthorLast, F. (Year). *Title of the paper*. Retrieved from URL'\n",
        "\n",
        "For multiple authors, we list up to 3 (or use ‚Äúet al.‚Äù after that for simplicity)."
      ],
      "metadata": {
        "id": "EfUzu1PeO9ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_apa_citation(paper):\n",
        "    authors = paper.get(\"authors\", [])\n",
        "    if not authors:\n",
        "        author_part = \"Unknown\"\n",
        "    elif len(authors) == 1:\n",
        "        author_part = authors[0]\n",
        "    elif len(authors) == 2:\n",
        "        author_part = f\"{authors[0]} & {authors[1]}\"\n",
        "    elif len(authors) == 3:\n",
        "        author_part = f\"{authors[0]}, {authors[1]}, & {authors[2]}\"\n",
        "    else:\n",
        "        author_part = f\"{authors[0]} et al.\"\n",
        "\n",
        "    year = paper.get(\"year\", \"n.d.\")\n",
        "    title = paper.get(\"title\", \"Untitled\")\n",
        "    url = paper.get(\"url\", \"\")\n",
        "\n",
        "    citation = f\"{author_part} ({year}). *{title}*. Retrieved from {url}\"\n",
        "    return citation\n",
        "\n",
        "#Integrate with Memory Buffer - extend the memory buffer to store the citation:\n",
        "\n",
        "def store_citation(self, session_id, paper_id, citation):\n",
        "    for paper in self.memory.get(session_id, {}).get(\"papers\", []):\n",
        "        if paper[\"id\"] == paper_id:\n",
        "            paper[\"citation\"] = citation\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "#You‚Äôd then use it like this:\n",
        "\n",
        "\n",
        "for paper in buffer.get_papers(session):\n",
        "    citation = format_apa_citation(paper)\n",
        "    buffer.store_citation(session, paper[\"id\"], citation)\n",
        "    print(\"üìÑ APA Citation:\", citation)\n"
      ],
      "metadata": {
        "id": "eGqrwNdIPspg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_processor(\"Find and summarize papers on AI in agriculture and generate citations and cite.\"))"
      ],
      "metadata": {
        "id": "a2PgaxU3aqVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODULE 6: ReAct Controller (Reasoning and Acting Loop)**\n",
        "\n",
        "Create a simple controller that:\n",
        "\n",
        "1. Thinks step-by-step\n",
        "2. Chooses which tool to use (search, summarize, cite)\n",
        "3. Stores and tracks what‚Äôs done\n",
        "4. Generates a final output"
      ],
      "metadata": {
        "id": "JFizRW5PRLoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "buffer = MemoryBuffer()\n",
        "\n",
        "#Define ReAct Agent\n",
        "def react_agent(user_input):\n",
        "    output_log = []\n",
        "    output_log.append(\"ü§î Thought: Understanding user request...\")\n",
        "    tasks = input_processor(user_input)\n",
        "    output_log.append(f\"üß† Detected tasks: {tasks}\")\n",
        "\n",
        "    session_id = None\n",
        "    paper_results = []\n",
        "\n",
        "    if \"search\" in tasks:\n",
        "        output_log.append(\"üîç Action: Searching for papers...\")\n",
        "        results = search_semantic_scholar(user_input)\n",
        "        if \"error\" in results:\n",
        "            return f\"‚ùå Observation: {results['error']}\"\n",
        "        paper_results = results[\"papers\"]\n",
        "        session_id = buffer.store_papers(user_input, paper_results)\n",
        "        output_log.append(f\"üì¶ Observation: {len(paper_results)} papers stored in session {session_id}\")\n",
        "    else: # If no search task, check if there's an active session to use\n",
        "        # In a more complex agent, you might have logic to retrieve the latest session\n",
        "        # For simplicity here, we assume if no search, user might be referring to the last search\n",
        "        # This is a placeholder and can be improved\n",
        "        latest_session_id = list(buffer.memory.keys())[-1] if buffer.memory else None\n",
        "        if latest_session_id:\n",
        "          session_id = latest_session_id\n",
        "          output_log.append(f\"üì¶ Observation: Using existing session {session_id}\")\n",
        "        else:\n",
        "          return \"‚ö†Ô∏è Please perform a search first before summarizing or citing.\"\n",
        "\n",
        "\n",
        "    if \"connect\" in tasks and session_id:\n",
        "        output_log.append(\"üîó Action: Identifying connections between sources...\")\n",
        "        # Implement connection logic or a placeholder\n",
        "        output_log.append(\"üîó (Connection logic not yet implemented)\")\n",
        "\n",
        "    if \"summarize\" in tasks and session_id:\n",
        "        output_log.append(\"üìù Action: Summarizing papers...\")\n",
        "        for paper in buffer.get_papers(session_id):\n",
        "            summary = summarize_text(paper['abstract'])\n",
        "            buffer.store_summary(session_id, paper['id'], summary)\n",
        "            output_log.append(f\"\\nüìò {paper['title']}\\nüîç Summary: {summary}\")\n",
        "\n",
        "    if \"cite\" in tasks and session_id:\n",
        "        output_log.append(\"üìÑ Action: Generating citations...\")\n",
        "        for paper in buffer.get_papers(session_id):\n",
        "            citation = format_apa_citation(paper)\n",
        "            buffer.store_citation(session_id, paper['id'], citation)\n",
        "            output_log.append(f\"\\nüìò {paper['title']}\\nüìÑ Citation: {citation}\")\n",
        "\n",
        "    # Remove this redundant check\n",
        "    # if not session_id:\n",
        "    #     return \"ü§∑‚Äç‚ôÇÔ∏è I couldn't process your request. Try rephrasing.\"\n",
        "\n",
        "    output_log.append(f\"\\n‚úÖ Session complete. Session ID: {session_id}\")\n",
        "    return \"\\n\".join(output_log)\n",
        "\n",
        "# This goes outside the function:\n",
        "print(react_agent(\"machine learning in healthcare.\"))"
      ],
      "metadata": {
        "id": "4nwBgo4QRW6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding a simple Gradio interface so user can interact with AI Virtual Research Agent from a web-based UI inside Google Colab.**"
      ],
      "metadata": {
        "id": "zm8UrrlxUpzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1: Install Gradio\n",
        "!pip install gradio --quiet\n",
        "import gradio as gr\n",
        "\n",
        "#Step 2: Define a Wrapper Function\n",
        "#This wraps the react_agent() function into something Gradio can use.\n",
        "\n",
        "def assistant_interface(user_input):\n",
        "    try:\n",
        "        output = react_agent(user_input)\n",
        "        return output\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "#Step 3: Build the Gradio Interface\n",
        "#Here‚Äôs a UI with:\n",
        "#   1. An input box\n",
        "#   2. A \"Submit\" button\n",
        "#   3. Scrollable chatbot-like output\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ü§ñ Academic Research Assistant\")\n",
        "    gr.Markdown(\"Ask for papers, summaries, and citations. Try: 'Find papers on AI in healthcare and summarize them.'\")\n",
        "\n",
        "    user_input = gr.Textbox(label=\"Enter your request\")\n",
        "    output_box = gr.Textbox(label=\"Agent Response\", lines=20)\n",
        "\n",
        "    submit_button = gr.Button(\"Run Agent\")\n",
        "\n",
        "    submit_button.click(fn=assistant_interface, inputs=user_input, outputs=output_box)\n",
        "\n",
        "# Step 4: Launch the Interface\n",
        "demo.launch(share=True)\n",
        "\n",
        "#üîó share=True gives you a public link to test the agent outside of Colab too!\n",
        "\n"
      ],
      "metadata": {
        "id": "Xrni0dLDUzVX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}